{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f8033bc-a8f9-469e-8c52-9fe44357f0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import time\n",
    "device = 'mps' if torch.backends.mps.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c432ed5-69f7-4875-b836-5d8aab357323",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 0.00685120\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "# matrix operations here\n",
    "zeros = torch.zeros(1, 1)\n",
    "end_time = time.time()\n",
    "\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Elapsed time: {elapsed_time:.8f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f08173e-473b-4357-8fbb-b98dc98d22c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU: 0.58735514\n",
      "CPU: 0.28589272\n",
      "CPU times: user 2.17 s, sys: 811 ms, total: 2.98 s\n",
      "Wall time: 3.23 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Init rands for gpu and cpu\n",
    "torch_rand1 = torch.rand(100, 100, 100, 100).to(device)\n",
    "torch_rand2 = torch.rand(100, 100, 100, 100).to(device)\n",
    "np_rand1 = torch.rand(100, 100, 100, 100)\n",
    "np_rand2 = torch.rand(100, 100, 100, 100)\n",
    "\n",
    "# GPU test\n",
    "start_time = time.time()\n",
    "\n",
    "rand = torch_rand1 @ torch_rand2\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"GPU: {elapsed_time:.8f}\")\n",
    "\n",
    "# CPU test\n",
    "start_time = time.time()\n",
    "\n",
    "rand = np.multiply(np_rand1, np_rand2)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"CPU: {elapsed_time:.8f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "184e9732-d60b-4ca5-8b19-869ec0c27c18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "# Probability tensor\n",
    "probabilities = torch.tensor([0.1, 0.9]) # 10% -> 0 and 90% -> 1\n",
    "# Draw 5 samples from the multinomial distribution\n",
    "samples = torch.multinomial(probabilities, num_samples=10, replacement=True)\n",
    "print(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9d3c561-f407-4237-9971-e67fb93c7ef1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0., 0.],\n",
       "        [1., 1., 0., 0., 0.],\n",
       "        [1., 1., 1., 0., 0.],\n",
       "        [1., 1., 1., 1., 0.],\n",
       "        [1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tril(torch.ones(5, 5)) # Triangle lower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ddc2493-45d7-41b7-994c-5f0574d731e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1., 1.],\n",
       "        [0., 1., 1., 1., 1.],\n",
       "        [0., 0., 1., 1., 1.],\n",
       "        [0., 0., 0., 1., 1.],\n",
       "        [0., 0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.triu(torch.ones(5,5)) # Triangle upper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a51a5f11-bb12-4897-a155-a39166dfca7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., -inf, -inf, -inf, -inf],\n",
       "        [0., 0., -inf, -inf, -inf],\n",
       "        [0., 0., 0., -inf, -inf],\n",
       "        [0., 0., 0., 0., -inf],\n",
       "        [0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Whatever hits the condition will be filled up with second argument of masked fill\n",
    "out = torch.zeros(5, 5).masked_fill(torch.tril(torch.ones(5, 5)) == 0, float(\"-inf\"))\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ae5248a-e303-41ee-81f4-13545db7484f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0., 0.],\n",
       "        [1., 1., 0., 0., 0.],\n",
       "        [1., 1., 1., 0., 0.],\n",
       "        [1., 1., 1., 1., 0.],\n",
       "        [1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.exp(out) # Exponent of it all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bf06f2f3-39e3-4afb-a1ab-110fd927dcec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 3, 2])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = torch.zeros(2, 3, 4)\n",
    "out = input.transpose(0, 2) # Swap the \"first\" dimension (2) with the third dimension (4)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4c2dc1fd-73af-4606-9c2a-0bca2c0bc420",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n"
     ]
    }
   ],
   "source": [
    "tensor1 = torch.tensor([1,2,3])\n",
    "tensor2 = torch.tensor([4,5,6])\n",
    "# Stack tensors along new dimension\n",
    "stacked_tensor = torch.stack([tensor1, tensor2])\n",
    "print(stacked_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ea2087f2-0cc9-4dcc-abaf-d2cd26c41471",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.5121, -2.1811, -0.3813], grad_fn=<SqueezeBackward4>)\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "sample = torch.tensor([10., 10., 10.])\n",
    "linear = nn.Linear(3, 3, bias=False)\n",
    "print(linear(sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aea809df-0074-408b-97da-5c9811530b0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0900, 0.2447, 0.6652])\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "sample_tensor = torch.tensor([1., 2., 3.])\n",
    "\n",
    "softmax_output = F.softmax(sample_tensor, dim=0)\n",
    "\n",
    "print(softmax_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6702ba23-afe9-4c5d-995e-77f3eece0b63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 5])\n"
     ]
    }
   ],
   "source": [
    "# Suppose we have 10 words in our 'vocabulary', and we want to embed them into 5-dimensional space.\n",
    "vocab_size = 10\n",
    "embed_dim = 5\n",
    "\n",
    "# Create an embedding object\n",
    "embedding = nn.Embedding(num_embeddings=vocab_size, embedding_dim=embed_dim)\n",
    "\n",
    "# Example indices representing words in our vocabulary\n",
    "word_indices = torch.tensor([1, 2, 8, 6], dtype=torch.long)\n",
    "\n",
    "# Get the embeddings for these words\n",
    "embedded_output = embedding(word_indices)\n",
    "\n",
    "print(embedded_output.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4d715a4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0657,  0.4454, -0.2327,  0.0396,  0.1267],\n",
      "        [-1.7355,  0.9334,  0.5152,  0.2259, -0.8137],\n",
      "        [ 0.5708,  0.9402,  0.1450, -1.2770,  0.0062],\n",
      "        [ 0.9000,  1.0809,  0.7363, -0.7177, -0.0598]],\n",
      "       grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# This is like saying, \"Hey computer, we have 10 different words.\"\n",
    "vocab_size = 10\n",
    "\n",
    "# This is like saying, \"Turn each word into a sticker with 5 different spots on it.\"\n",
    "embed_dim = 5\n",
    "\n",
    "# This is our magical sticker machine. It knows how to turn words into stickers.\n",
    "embedding = nn.Embedding(num_embeddings=vocab_size, embedding_dim=embed_dim)\n",
    "\n",
    "# These are the numbers for some words we want to turn into stickers.\n",
    "word_numbers = [1, 2, 8, 6]\n",
    "\n",
    "# This tells the machine to do its magic and give us the stickers.\n",
    "stickers = embedding(torch.tensor(word_numbers))\n",
    "\n",
    "# Now we can look at our stickers!\n",
    "print(stickers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e3c178",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu kernel",
   "language": "python",
   "name": "gpu_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
